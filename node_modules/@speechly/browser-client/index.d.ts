
/**
 * The interface for a client for Speechly SLU WebSocket API.
 * @public
 */
export declare interface APIClient {
    /**
     * Registers a callback that is invoked whenever a response is received from the API.
     *
     * @param cb - this callback to invoke.
     */
    onResponse(cb: ResponseCallback): void;
    /**
     * Registers a callback that is invoked whenever WebSocket connection is closed (either normally or due to an error).
     *
     * @param cb - the callback to invoke.
     */
    onClose(cb: CloseCallback): void;
    /**
     * Initialises the client.
     *
     * This method will be called by the Client as part of the initialisation process.
     *
     * @param apiUrl - url.
     * @param authToken - authentication token.
     * @param targetSampleRate - target sample rate of audio.
     * @param debug - debug flag.
     */
    initialize(apiUrl: string, authToken: string, targetSampleRate: number, debug: boolean): Promise<void>;
    /**
     * Initialises the client.
     *
     * This should prepare websocket to be used (set source sample rate).
     * This method will be called by the Client as part of the initialisation process.
     *
     * @param sourceSampleRate - sample rate of audio source.
     */
    setSourceSampleRate(sourceSampleRate: number): Promise<void>;
    /**
     * Closes the client.
     *
     * This should close the connection and tear down all infrastructure related to it.
     * Calling `initialize` again after calling `close` should be possible.
     */
    close(): Promise<void>;
    /**
     * Starts a new audio context by sending the start event to the API.
     * The promise returned should resolve or reject after the API has responded with confirmation or an error has occured.
     */
    startContext(appId?: string): Promise<string>;
    /**
     * Stops an audio context by sending the stop event to the API.
     * The promise returned should resolve or reject after the API has responded with confirmation or an error has occured.
     */
    stopContext(): Promise<string>;
    /**
     * Stops current context and immediately starts a new SLU context
     * by sending a start context event to the API and unmuting the microphone.
     */
    switchContext(appId: string): Promise<string>;
    /**
     * Sends audio to the API.
     * If there is no active context (no successful previous calls to `startContext`), this must fail.
     *
     * @param audioChunk - audio chunk to send.
     */
    sendAudio(audioChunk: Float32Array): void;
    /**
     * Sends message to the Worker.
     *
     * @param message - message to send.
     */
    postMessage(message: Object): void;
}

/**
 * A callback that receives an ArrayBuffer representing a frame of audio.
 * @public
 */
export declare type AudioCallback = (audioBuffer: Int16Array) => void;

/**
 * A client for Speechly Spoken Language Understanding (SLU) API. The client handles initializing the microphone
 * and websocket connection to Speechly API, passing control events and audio stream to the API, reading the responses
 * and dispatching them, as well as providing a high-level API for interacting with so-called speech segments.
 * @public
 */
export declare class Client {
    private readonly debug;
    private readonly logSegments;
    private readonly projectId?;
    private readonly appId?;
    private readonly storage;
    private readonly microphone;
    private readonly apiClient;
    private readonly loginUrl;
    private readonly isWebkit;
    private readonly sampleRate;
    private readonly nativeResamplingSupported;
    private readonly activeContexts;
    private readonly reconnectAttemptCount;
    private readonly reconnectMinDelay;
    private readonly contextStopDelay;
    private stoppedContextIdPromise?;
    private initializeMicrophonePromise?;
    private readonly initializeApiClientPromise;
    private resolveInitialization?;
    private resolveStopContext?;
    private readonly deviceId;
    private authToken?;
    private audioContext?;
    private state;
    private stateChangeCb;
    private segmentChangeCb;
    private tentativeTranscriptCb;
    private tentativeEntitiesCb;
    private tentativeIntentCb;
    private transcriptCb;
    private entityCb;
    private intentCb;
    constructor(options: ClientOptions);
    /**
     * Esteblish websocket connection
     */
    private connect;
    /**
     * Initializes the client, by initializing the microphone and establishing connection to the API.
     *
     * This function HAS to be invoked by a user by e.g. binding it to a button press,
     * or some other user-performed action.
     *
     * If this function is invoked without a user interaction,
     * the microphone functionality will not work due to security restrictions by the browser.
     */
    initialize(): Promise<void>;
    /**
     * Closes the client by closing the API connection and disabling the microphone.
     */
    close(): Promise<void>;
    /**
     * Stops current context and immediately starts a new SLU context
     * by sending a start context event to the API and unmuting the microphone.
     * @param appId - unique identifier of an app in the dashboard.
     */
    switchContext(appId: string): Promise<void>;
    /**
     * Starts a new SLU context by sending a start context event to the API and unmuting the microphone.
     * @param cb - the callback which is invoked when the context start was acknowledged by the API.
     */
    startContext(appId?: string): Promise<string>;
    private _startContext;
    /**
     * Stops current SLU context by sending a stop context event to the API and muting the microphone
     * delayed by contextStopDelay = 250 ms
     */
    stopContext(): Promise<string>;
    private _stopContext;
    /**
     * Adds a listener for client state change events.
     * @param cb - the callback to invoke on state change events.
     */
    onStateChange(cb: StateChangeCallback): void;
    /**
     * Adds a listener for current segment change events.
     * @param cb - the callback to invoke on segment change events.
     */
    onSegmentChange(cb: SegmentChangeCallback): void;
    /**
     * Adds a listener for tentative transcript responses from the API.
     * @param cb - the callback to invoke on a tentative transcript response.
     */
    onTentativeTranscript(cb: TentativeTranscriptCallback): void;
    /**
     * Adds a listener for transcript responses from the API.
     * @param cb - the callback to invoke on a transcript response.
     */
    onTranscript(cb: TranscriptCallback): void;
    /**
     * Adds a listener for tentative entities responses from the API.
     * @param cb - the callback to invoke on a tentative entities response.
     */
    onTentativeEntities(cb: TentativeEntitiesCallback): void;
    /**
     * Adds a listener for entity responses from the API.
     * @param cb - the callback to invoke on an entity response.
     */
    onEntity(cb: EntityCallback): void;
    /**
     * Adds a listener for tentative intent responses from the API.
     * @param cb - the callback to invoke on a tentative intent response.
     */
    onTentativeIntent(cb: IntentCallback): void;
    /**
     * Adds a listener for intent responses from the API.
     * @param cb - the callback to invoke on an intent response.
     */
    onIntent(cb: IntentCallback): void;
    private readonly handleWebsocketResponse;
    private readonly handleWebsocketClosure;
    private reconnectWebsocket;
    private setState;
}

/**
 * The options which can be used to configure the client.
 * @public
 */
export declare interface ClientOptions {
    /**
     * The unique identifier of an app in the dashboard.
     */
    appId?: string;
    /**
     * The unique identifier of a project in the dashboard.
     */
    projectId?: string;
    /**
     * The language which is used by the app.
     */
    language?: string;
    /**
     * The URL of Speechly login endpoint.
     */
    loginUrl?: string;
    /**
     * The URL of Speechly SLU API endpoint.
     */
    apiUrl?: string;
    /**
     * The sample rate of the audio to use.
     */
    sampleRate?: number;
    /**
     * Whether to output debug statements to the console.
     */
    debug?: boolean;
    /**
     * Whether to output updated segments to the console.
     */
    logSegments?: boolean;
    /**
     * Custom microphone implementation.
     * If not provided, an implementation based on getUserMedia and Web Audio API is used.
     */
    microphone?: Microphone;
    /**
     * Custom API client implementation.
     * If not provided, an implementation based on Speechly SLU WebSocket API is used.
     */
    apiClient?: APIClient;
    /**
     * Custom storage implementation.
     * If not provided, browser's LocalStorage API is used.
     */
    storage?: Storage_2;
}

/**
 * All possible states of a Speechly API client. Failed, NoBrowserSupport and NoAudioConsent states are non-recoverable
 * erroneous states, which should be handled by the end user, according to the semantics of an application.
 * Other states can also be utilized for e.g. enabling and disabling recording buttons or showing the status in the app.
 * It is also possible to use arithmetics for state comparison, e.g. `if (state < speechly.ClientState.Disconnected)`,
 * to react to non-recoverable states.
 * @public
 */
export declare enum ClientState {
    Failed = 0,
    NoBrowserSupport = 1,
    NoAudioConsent = 2,
    Disconnected = 3,
    Disconnecting = 4,
    Connecting = 5,
    Connected = 6,
    Starting = 7,
    Stopping = 8,
    Recording = 9
}

/**
 * A callback that is invoked whenever WebSocket connection is closed.
 * @public
 */
export declare type CloseCallback = (err: Error) => void;

/**
 * Default sample rate for microphone streams.
 * @public
 */
export declare const DefaultSampleRate = 16000;

/**
 * A single entity detected by the SLU API.
 * @public
 */
export declare interface Entity {
    /**
     * The type specified by the developer in the NLU rules in the dashboard (e.g. restaurant_type).
     */
    type: string;
    /**
     * The value of the entity (e.g. Papa Joe's).
     */
    value: string;
    /**
     * The index of the first word that contains this entity.
     */
    startPosition: number;
    /**
     * The index of the last word that contains this entity.
     */
    endPosition: number;
    /**
     * Whether the entity was detected as final.
     */
    isFinal: boolean;
}

/**
 * A callback that is invoked whenever new entity is received from the API.
 * @public
 */
export declare type EntityCallback = (contextId: string, segmentId: number, entity: Entity) => void;

/**
 * Entity response payload.
 * @public
 */
export declare interface EntityResponse {
    /**
     * Entity type (e.g. restaurant, direction, room, device).
     */
    entity: string;
    /**
     * Entity value (e.g. "sushi bar", "northwest", "living room", "kitchen lights").
     */
    value: string;
    /**
     * Start position of the entity in the segment. Correlates with TranscriptResponse indices.
     * Inclusive.
     */
    start_position: number;
    /**
     * End position of the entity in the segment. Correlates with TranscriptResponse indices.
     * Exclusive.
     */
    end_position: number;
}

/**
 * Error to be thrown when the initialize method of a Microphone instance is called more than once.
 * @public
 */
export declare const ErrAlreadyInitialized: Error;

/**
 * Error to be thrown when the device does not support the Microphone instance's target audio APIs.
 * @public
 */
export declare const ErrDeviceNotSupported: Error;

/**
 * Error to be thrown if requested key was not found in the storage.
 * @public
 */
export declare const ErrKeyNotFound: Error;

/**
 * Error to be thrown when user did not give consent to the application to record audio.
 * @public
 */
export declare const ErrNoAudioConsent: Error;

/**
 * Error to be thrown if storage API is not supported by the device.
 * @public
 */
export declare const ErrNoStorageSupport: Error;

/**
 * Error to be thrown when the microphone was accessed before it was initialized.
 * @public
 */
export declare const ErrNotInitialized: Error;

/**
 * The intent detected by the SLU API.
 * @public
 */
export declare interface Intent {
    /**
     * The value of the intent.
     */
    intent: string;
    /**
     * Whether the intent was detected as final.
     */
    isFinal: boolean;
}

/**
 * A callback that is invoked whenever new intent (tentative or not) is received from the API.
 * @public
 */
export declare type IntentCallback = (contextId: string, segmentId: number, intent: Intent) => void;

/**
 * Intent response payload.
 * @public
 */
export declare interface IntentResponse {
    /**
     * Intent type (e.g. "book", "find", "turn_on").
     */
    intent: string;
}

/**
 * The interface for a microphone.
 * @public
 */
export declare interface Microphone {
    /**
     * Initialises the microphone.
     *
     * This should prepare the microphone infrastructure for receiving audio chunks,
     * but the microphone should remain muted after the call.
     * This method will be called by the Client as part of client initialisation process.
     */
    initialize(audioContext: AudioContext, opts: MediaStreamConstraints): Promise<void>;
    /**
     * Closes the microphone, tearing down all the infrastructure.
     *
     * The microphone should stop emitting audio after this is called.
     * Calling `initialize` again after calling `close` should succeed and make microphone ready to use again.
     * This method will be called by the Client as part of client closure process.
     */
    close(): Promise<void>;
    /**
     * Mutes the microphone. If the microphone is muted, the `onAudio` callbacks should not be called.
     */
    mute(): void;
    /**
     * Unmutes the microphone.
     */
    unmute(): void;
}

/**
 * A callback that is invoked whenever a response is received from Speechly SLU WebSocket API.
 * @public
 */
export declare type ResponseCallback = (response: WebsocketResponse) => void;

/**
 * The smallest component of SLU API, defined by an intent.
 * @public
 */
export declare interface Segment {
    /**
     * The identifier of parent SLU context.
     */
    contextId: string;
    /**
     * The identifier of the segment within the parent context.
     */
    id: number;
    /**
     * Whether the segment is final. A final segment is guaranteed to only contain final parts.
     */
    isFinal: boolean;
    /**
     * The intent of the segment.
     */
    intent: Intent;
    /**
     * All words which belong to the segment, ordered by their indices.
     */
    words: Word[];
    /**
     * All entities which belong to the segment, not ordered.
     */
    entities: Entity[];
}

/**
 * A callback that is invoked whenever current {@link Segment | segment} changes.
 * @public
 */
export declare type SegmentChangeCallback = (segment: Segment) => void;

/**
 * A callback that is invoked whenever the {@link ClientState | client state} changes.
 * @public
 */
export declare type StateChangeCallback = (state: ClientState) => void;

/**
 * Converts client state value to a string, which could be useful for debugging or metrics.
 * @param state - the state of the client
 * @public
 */
export declare function stateToString(state: ClientState): string;

/**
 * The interface for local key-value storage.
 * @public
 */
declare interface Storage_2 {
    /**
     * Retrieves a key from the storage.
     *
     * @param key - the key to retrieve
     */
    get(key: string): string | null;
    /**
     * Adds a key to the storage, possibly overwriting existing value.
     *
     * @param key - the key to write
     * @param val - the value to write
     */
    set(key: string, val: string): void;
    /**
     * Adds a key to the storage, possibly overwriting existing value.
     *
     * @param key - the key to write
     * @param genFn - generator function that will be invoked if the key cannot be found in the storage.
     * The return value of the function will be used as the value that will be stored under the given key.
     */
    getOrSet(key: string, genFn: () => string): string;
}
export { Storage_2 as Storage }

/**
 * A callback that is invoked whenever new tentative entities are received from the API.
 * @public
 */
export declare type TentativeEntitiesCallback = (contextId: string, segmentId: number, entities: Entity[]) => void;

/**
 * Tenative entities response payload.
 * @public
 */
export declare interface TentativeEntitiesResponse {
    /**
     * Individual entities.
     */
    entities: EntityResponse[];
}

/**
 * A callback that is invoked whenever a new tentative transcript is received from the API.
 * @public
 */
export declare type TentativeTranscriptCallback = (contextId: string, segmentId: number, words: Word[], text: string) => void;

/**
 * Tentative transcript response payload.
 * @public
 */
export declare interface TentativeTranscriptResponse {
    /**
     * Transcript text, i.e. the full transcript of the audio to-date.
     */
    transcript: string;
    /**
     * Individual transcript words.
     */
    words: TranscriptResponse[];
}

/**
 * A callback that is invoked whenever a new transcript is received from the API.
 * @public
 */
export declare type TranscriptCallback = (contextId: string, segmentId: number, word: Word) => void;

/**
 * Transcript response payload.
 * @public
 */
export declare interface TranscriptResponse {
    /**
     * Transcripted word.
     */
    word: string;
    /**
     * The index of the transcripted word in the segment.
     */
    index: number;
    /**
     * Start timestamp of the transcript in the audio stream in milliseconds.
     */
    start_timestamp: number;
    /**
     * End timestamp of the transcript in the audio stream in milliseconds.
     */
    end_timestamp: number;
}

/**
 * The interface for response returned by WebSocket client.
 * @public
 */
export declare interface WebsocketResponse {
    /**
     * Response type.
     */
    type: WebsocketResponseType;
    /**
     * Audio context ID.
     */
    audio_context: string;
    /**
     * Segment ID.
     */
    segment_id: number;
    /**
     * Response payload.
     *
     * The payload value should match the response type (i.e. TranscriptResponse should have Transcript type).
     * Not all response types have payloads - Started, Stopped and SegmentEnd don't have payloads.
     * TentativeIntent and Intent share the same payload interface (IntentResponse).
     */
    data: TranscriptResponse | EntityResponse | IntentResponse | TentativeTranscriptResponse | TentativeEntitiesResponse;
}

/**
 * Known WebSocket response types.
 * @public
 */
export declare enum WebsocketResponseType {
    Opened = "WEBSOCKET_OPEN",
    SourceSampleRateSetSuccess = "SOURSE_SAMPLE_RATE_SET_SUCCESS",
    Started = "started",
    Stopped = "stopped",
    SegmentEnd = "segment_end",
    Transcript = "transcript",
    Entity = "entity",
    Intent = "intent",
    TentativeTranscript = "tentative_transcript",
    TentativeEntities = "tentative_entities",
    TentativeIntent = "tentative_intent"
}

/**
 * A single word detected by the SLU API.
 * @public
 */
export declare interface Word {
    /**
     * The value of the word.
     */
    value: string;
    /**
     * The index of the word within a segment.
     */
    index: number;
    /**
     * Start timestamp of the word within the audio of the context.
     */
    startTimestamp: number;
    /**
     * End timestamp of the word within the audio of the context.
     */
    endTimestamp: number;
    /**
     * Whether the word was detected as final.
     */
    isFinal: boolean;
}

export { }
