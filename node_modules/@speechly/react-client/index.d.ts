import { Client } from '@speechly/browser-client';
import { ClientOptions } from '@speechly/browser-client';
import { ClientState } from '@speechly/browser-client';
import { Entity } from '@speechly/browser-client';
import { Intent } from '@speechly/browser-client';
import { default as React_2 } from 'react';
import { Segment as SpeechSegment } from '@speechly/browser-client';
import { Word } from '@speechly/browser-client';

/**
 * Signature for initialise and toggleRecording functions.
 * @public
 */
export declare type ContextFunc = () => Promise<void>;
export { Entity }
export { Intent }

/**
 * A React context that holds the state of Speechly SLU API client.
 * @public
 */
export declare const SpeechContext: React_2.Context<SpeechContextState>;

/**
 * The state of SpeechContext.
 *
 * Functions to initialise audio and recording as well as the state are always present,
 * however the values returned from the API will only be present when they are returned from the API.
 *
 * Individual values (transcripts, entities and intent) are reset back to undefined after current segment is finalised.
 * @public
 */
export declare interface SpeechContextState {
    /**
     * Function that initialises Speechly client, including both the API connection and the audio initialisation.
     *
     * It is optional and you don't have to call it manually,
     * it will be called automatically upon the first call to toggleRecording.
     *
     * The idea is that it provides a more fine-grained control over how the audio is initialised,
     * in case you want to give the user more control over your app.
     */
    initialise: ContextFunc;
    /**
     * Toggles recording on or off. Automatically initialises the API connection and audio stack.
     */
    toggleRecording: ContextFunc;
    /**
     * Switch appId in multi-app project.
     */
    switchApp: (appId: string) => void;
    /**
     * Current appId in multi-app project.
     */
    appId?: string;
    /**
     * Current state of the context, whether it's idle, recording or failed, etc.
     * It's advised to react to this to enable / disable voice functionality in your app
     * as well as inidicate to the user that recording is in progress or results are being fetched from the API.
     */
    speechState: SpeechState;
    /**
     * Last tentative transcript received from the API. Resets after current segment is finalised.
     */
    tentativeTranscript?: TentativeSpeechTranscript;
    /**
     * Last tentative entities received from the API. Resets after current segment is finalised.
     */
    tentativeEntities?: TentativeSpeechEntities;
    /**
     * Last tentative intent received from the API. Resets after current segment is finalised.
     */
    tentativeIntent?: TentativeSpeechIntent;
    /**
     * Last final transcript received from the API. Resets after current segment is finalised.
     */
    transcript?: SpeechTranscript;
    /**
     * Last final entity received from the API. Resets after current segment is finalised.
     */
    entity?: SpeechEntity;
    /**
     * Last final intent received from the API. Resets after current segment is finalised.
     */
    intent?: SpeechIntent;
    /**
     * Last segment received from the API.
     */
    segment?: SpeechSegment;
}

/**
 * Wraps the final entity response from the API.
 * @public
 */
export declare type SpeechEntity = {
    contextId: string;
    segmentId: number;
    entity: Entity;
};

/**
 * Wraps the final intent response from the API.
 * @public
 */
export declare type SpeechIntent = {
    contextId: string;
    segmentId: number;
    intent: Intent;
};

/**
 * The provider for SpeechContext.
 *
 * Make sure you have only one SpeechProvider in your application,
 * because otherwise the audio will be mixed up and unusable.
 *
 * It is possible to switch the props on the fly, which will make provider stop current client if it's running
 * and start a new one.
 * @public
 */
export declare class SpeechProvider extends React_2.Component<SpeechProviderProps, SpeechProviderState> {
    constructor(props: SpeechProviderProps);
    readonly initialiseAudio: () => Promise<void>;
    readonly startContext: () => Promise<void>;
    readonly stopContext: () => Promise<void>;
    readonly toggleRecording: () => Promise<void>;
    readonly switchApp: (appId: string) => Promise<void>;
    render(): JSX.Element;
    componentDidUpdate(prevProps: SpeechProviderProps): Promise<void>;
    componentWillUnmount(): Promise<void>;
    private readonly initialiseClient;
    private readonly onClientStateChange;
    private readonly onSegmentChange;
    private readonly onTentativeTranscript;
    private readonly onTranscript;
    private readonly onTentativeEntities;
    private readonly onEntity;
    private readonly onTentativeIntent;
    private readonly onIntent;
}

/**
 * Props for SpeechContext provider, which are used to initialise API client.
 * @public
 */
export declare interface SpeechProviderProps extends ClientOptions {
    /**
     * Whether to disable reacting to tentative items. Set this to true if you don't use them.
     */
    disableTenative?: boolean;
}

declare interface SpeechProviderState {
    client: Client;
    clientState: ClientState;
    recordingState: SpeechState;
    toggleIsOn: boolean;
    appId?: string;
    startedContextPromise?: Promise<string>;
    segment?: SpeechSegment;
    tentativeTranscript?: TentativeSpeechTranscript;
    transcript?: SpeechTranscript;
    tentativeEntities?: TentativeSpeechEntities;
    entity?: SpeechEntity;
    tentativeIntent?: TentativeSpeechIntent;
    intent?: SpeechIntent;
}
export { SpeechSegment }

/**
 * The state of SpeechContext.
 * @public
 */
export declare enum SpeechState {
    /**
     * The context is in a state of unrecoverable error.
     * It is only possible to fix this by destroying and creating it from scratch.
     */
    Failed = "Failed",
    /**
     * Current browser is not supported by Speechly - it's not possible to use speech functionality.
     */
    NoBrowserSupport = "NoBrowserSupport",
    /**
     * The user did not provide permissions to use the microphone - it is not possible to use speech functionality.
     */
    NoAudioConsent = "NoAudioConsent",
    /**
     * The context has been created but not initialised. The audio and API connection are not enabled.
     */
    Idle = "Idle",
    /**
     * The context is connecting to the API.
     */
    Connecting = "Connecting",
    /**
     * The context is ready to use.
     */
    Ready = "Ready",
    /**
     * The context is current recording audio and sending it to the API for recognition.
     * The results are also being fetched.
     */
    Recording = "Recording",
    /**
     * The context is waiting for the API to finish sending trailing responses.
     * No audio is being sent anymore.
     */
    Loading = "Loading"
}

/**
 * Wraps the final transcript response from the API.
 * @public
 */
export declare type SpeechTranscript = {
    contextId: string;
    segmentId: number;
    word: Word;
};

/**
 * Wraps the tentative entities response from the API.
 * @public
 */
export declare type TentativeSpeechEntities = {
    contextId: string;
    segmentId: number;
    entities: Entity[];
};

/**
 * Wraps the tentative intent response from the API.
 * @public
 */
export declare type TentativeSpeechIntent = {
    contextId: string;
    segmentId: number;
    intent: Intent;
};

/**
 * Wraps the tentative transcript response from the API.
 * @public
 */
export declare type TentativeSpeechTranscript = {
    contextId: string;
    segmentId: number;
    words: Word[];
    text: string;
};

/**
 * React hook that exposes SpeechContext.
 * This is just an alias for useContext(SpeechContext).
 * @public
 */
export declare function useSpeechContext(): SpeechContextState;
export { Word }

export { }
