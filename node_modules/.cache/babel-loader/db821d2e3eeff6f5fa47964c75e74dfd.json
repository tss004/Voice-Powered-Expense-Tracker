{"ast":null,"code":"\"use strict\";\n\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\nvar __importDefault = this && this.__importDefault || function (mod) {\n  return mod && mod.__esModule ? mod : {\n    \"default\": mod\n  };\n};\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nconst types_1 = require(\"./types\");\n\nconst audioworklet_1 = __importDefault(require(\"./audioworklet\"));\n\nconst audioProcessEvent = 'audioprocess';\nconst baseBufferSize = 4096;\n\nclass BrowserMicrophone {\n  constructor(isWebkit, sampleRate, apiClient, debug = false) {\n    this.initialized = false;\n    this.muted = false;\n\n    this.handleAudio = array => {\n      if (this.muted) {\n        return;\n      }\n\n      if (array.length > 0) {\n        this.apiClient.sendAudio(array);\n      }\n    };\n\n    this.isWebkit = isWebkit;\n    this.apiClient = apiClient;\n    this.sampleRate = sampleRate;\n    this.debug = debug;\n  }\n\n  initialize(audioContext, opts) {\n    var _a;\n\n    return __awaiter(this, void 0, void 0, function* () {\n      if (((_a = window.navigator) === null || _a === void 0 ? void 0 : _a.mediaDevices) === undefined) {\n        throw types_1.ErrDeviceNotSupported;\n      }\n\n      this.audioContext = audioContext;\n      this.resampleRatio = this.audioContext.sampleRate / this.sampleRate;\n\n      try {\n        this.mediaStream = yield window.navigator.mediaDevices.getUserMedia(opts);\n      } catch (_b) {\n        throw types_1.ErrNoAudioConsent;\n      }\n\n      this.audioTrack = this.mediaStream.getAudioTracks()[0]; // Start audio context if we are dealing with a non-WebKit browser.\n      //\n      // Non-webkit browsers (currently only Chrome on Android)\n      // require that user media is obtained before resuming the audio context.\n      //\n      // If audio context is attempted to be resumed before `mediaDevices.getUserMedia`,\n      // `audioContext.resume()` will hang indefinitely, without being resolved or rejected.\n\n      if (!this.isWebkit) {\n        yield this.audioContext.resume();\n      }\n\n      if (window.AudioWorkletNode !== undefined) {\n        const blob = new Blob([audioworklet_1.default], {\n          type: 'text/javascript'\n        });\n        const blobURL = window.URL.createObjectURL(blob);\n        yield this.audioContext.audioWorklet.addModule(blobURL);\n        const speechlyNode = new AudioWorkletNode(this.audioContext, 'speechly-worklet');\n        this.audioContext.createMediaStreamSource(this.mediaStream).connect(speechlyNode);\n        speechlyNode.connect(this.audioContext.destination);\n\n        if (window.SharedArrayBuffer !== undefined) {\n          // Chrome, Edge, Firefox, Firefox Android\n          const controlSAB = new window.SharedArrayBuffer(4 * Int32Array.BYTES_PER_ELEMENT);\n          const dataSAB = new window.SharedArrayBuffer(1024 * Float32Array.BYTES_PER_ELEMENT);\n          this.apiClient.postMessage({\n            type: 'SET_SHARED_ARRAY_BUFFERS',\n            controlSAB,\n            dataSAB\n          });\n          speechlyNode.port.postMessage({\n            type: 'SET_SHARED_ARRAY_BUFFERS',\n            controlSAB,\n            dataSAB\n          });\n        } else {\n          if (this.debug) {\n            console.log('[SpeechlyClient]', 'can not use SharedArrayBuffer');\n          } // Opera, Chrome Android, Webview Anroid\n\n\n          speechlyNode.port.onmessage = event => {\n            this.handleAudio(event.data);\n          };\n        }\n      } else {\n        if (this.debug) {\n          console.log('[SpeechlyClient]', 'can not use AudioWorkletNode');\n        } // Safari, iOS Safari and Internet Explorer\n\n\n        if (this.isWebkit) {\n          // Multiply base buffer size of 4 kB by the resample ratio rounded up to the next power of 2.\n          // i.e. for 48 kHz to 16 kHz downsampling, this will be 4096 (base) * 4 = 16384.\n          const bufSize = baseBufferSize * Math.pow(2, Math.ceil(Math.log(this.resampleRatio) / Math.log(2)));\n          this.audioProcessor = this.audioContext.createScriptProcessor(bufSize, 1, 1);\n        } else {\n          this.audioProcessor = this.audioContext.createScriptProcessor(undefined, 1, 1);\n        }\n\n        this.audioContext.createMediaStreamSource(this.mediaStream).connect(this.audioProcessor);\n        this.audioProcessor.connect(this.audioContext.destination);\n        this.audioProcessor.addEventListener(audioProcessEvent, event => {\n          this.handleAudio(event.inputBuffer.getChannelData(0));\n        });\n      }\n\n      this.initialized = true;\n      this.mute();\n    });\n  }\n\n  close() {\n    return __awaiter(this, void 0, void 0, function* () {\n      this.mute();\n\n      if (!this.initialized) {\n        throw types_1.ErrNotInitialized;\n      }\n\n      const t = this.audioTrack;\n      t.enabled = false; // Stop all media tracks\n\n      const stream = this.mediaStream;\n      stream.getTracks().forEach(t => t.stop()); // Disconnect and stop ScriptProcessorNode\n\n      if (this.audioProcessor != null) {\n        const proc = this.audioProcessor;\n        proc.disconnect();\n      } // Unset all audio infrastructure\n\n\n      this.mediaStream = undefined;\n      this.audioTrack = undefined;\n      this.audioProcessor = undefined;\n      this.initialized = false;\n    });\n  }\n\n  mute() {\n    this.muted = true;\n  }\n\n  unmute() {\n    this.muted = false;\n  }\n\n}\n\nexports.BrowserMicrophone = BrowserMicrophone;","map":{"version":3,"sources":["../../src/microphone/browser_microphone.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA,MAAA,OAAA,GAAA,OAAA,CAAA,SAAA,CAAA;;AAEA,MAAA,cAAA,GAAA,eAAA,CAAA,OAAA,CAAA,gBAAA,CAAA,CAAA;;AAEA,MAAM,iBAAiB,GAAG,cAA1B;AACA,MAAM,cAAc,GAAG,IAAvB;;AAEA,MAAa,iBAAb,CAA8B;AAqB5B,EAAA,WAAA,CAAY,QAAZ,EAA+B,UAA/B,EAAmD,SAAnD,EAAyE,KAAA,GAAiB,KAA1F,EAA+F;AAfvF,SAAA,WAAA,GAAuB,KAAvB;AACA,SAAA,KAAA,GAAiB,KAAjB;;AAwIS,SAAA,WAAA,GAAe,KAAD,IAA8B;AAC3D,UAAI,KAAK,KAAT,EAAgB;AACd;AACD;;AACD,UAAI,KAAK,CAAC,MAAN,GAAe,CAAnB,EAAsB;AACpB,aAAK,SAAL,CAAe,SAAf,CAAyB,KAAzB;AACD;AACF,KAPgB;;AAzHf,SAAK,QAAL,GAAgB,QAAhB;AACA,SAAK,SAAL,GAAiB,SAAjB;AACA,SAAK,UAAL,GAAkB,UAAlB;AACA,SAAK,KAAL,GAAa,KAAb;AACD;;AAEK,EAAA,UAAU,CAAC,YAAD,EAA6B,IAA7B,EAAyD;;;;AACvE,UAAI,CAAA,CAAA,EAAA,GAAA,MAAM,CAAC,SAAP,MAAgB,IAAhB,IAAgB,EAAA,KAAA,KAAA,CAAhB,GAAgB,KAAA,CAAhB,GAAgB,EAAA,CAAE,YAAlB,MAAmC,SAAvC,EAAkD;AAChD,cAAM,OAAA,CAAA,qBAAN;AACD;;AAED,WAAK,YAAL,GAAoB,YAApB;AACA,WAAK,aAAL,GAAqB,KAAK,YAAL,CAAkB,UAAlB,GAA+B,KAAK,UAAzD;;AAEA,UAAI;AACF,aAAK,WAAL,GAAmB,MAAM,MAAM,CAAC,SAAP,CAAiB,YAAjB,CAA8B,YAA9B,CAA2C,IAA3C,CAAzB;AACD,OAFD,CAEE,OAAA,EAAA,EAAM;AACN,cAAM,OAAA,CAAA,iBAAN;AACD;;AAED,WAAK,UAAL,GAAkB,KAAK,WAAL,CAAiB,cAAjB,GAAkC,CAAlC,CAAlB,C,CAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,UAAI,CAAC,KAAK,QAAV,EAAoB;AAClB,cAAM,KAAK,YAAL,CAAkB,MAAlB,EAAN;AACD;;AAED,UAAI,MAAM,CAAC,gBAAP,KAA4B,SAAhC,EAA2C;AACzC,cAAM,IAAI,GAAG,IAAI,IAAJ,CAAS,CAAC,cAAA,CAAA,OAAD,CAAT,EAAyB;AAAE,UAAA,IAAI,EAAE;AAAR,SAAzB,CAAb;AACA,cAAM,OAAO,GAAG,MAAM,CAAC,GAAP,CAAW,eAAX,CAA2B,IAA3B,CAAhB;AACA,cAAM,KAAK,YAAL,CAAkB,YAAlB,CAA+B,SAA/B,CAAyC,OAAzC,CAAN;AACA,cAAM,YAAY,GAAG,IAAI,gBAAJ,CAAqB,KAAK,YAA1B,EAAwC,kBAAxC,CAArB;AACA,aAAK,YAAL,CAAkB,uBAAlB,CAA0C,KAAK,WAA/C,EAA4D,OAA5D,CAAoE,YAApE;AACA,QAAA,YAAY,CAAC,OAAb,CAAqB,KAAK,YAAL,CAAkB,WAAvC;;AACA,YAAI,MAAM,CAAC,iBAAP,KAA6B,SAAjC,EAA4C;AAC1C;AACA,gBAAM,UAAU,GAAG,IAAI,MAAM,CAAC,iBAAX,CAA6B,IAAI,UAAU,CAAC,iBAA5C,CAAnB;AACA,gBAAM,OAAO,GAAG,IAAI,MAAM,CAAC,iBAAX,CAA6B,OAAO,YAAY,CAAC,iBAAjD,CAAhB;AACA,eAAK,SAAL,CAAe,WAAf,CAA2B;AACzB,YAAA,IAAI,EAAE,0BADmB;AAEzB,YAAA,UAFyB;AAGzB,YAAA;AAHyB,WAA3B;AAKA,UAAA,YAAY,CAAC,IAAb,CAAkB,WAAlB,CAA8B;AAC5B,YAAA,IAAI,EAAE,0BADsB;AAE5B,YAAA,UAF4B;AAG5B,YAAA;AAH4B,WAA9B;AAKD,SAdD,MAcO;AACL,cAAI,KAAK,KAAT,EAAgB;AACd,YAAA,OAAO,CAAC,GAAR,CAAY,kBAAZ,EAAgC,+BAAhC;AACD,WAHI,CAIL;;;AACA,UAAA,YAAY,CAAC,IAAb,CAAkB,SAAlB,GAA+B,KAAD,IAAwB;AACpD,iBAAK,WAAL,CAAiB,KAAK,CAAC,IAAvB;AACD,WAFD;AAGD;AACF,OA9BD,MA8BO;AACL,YAAI,KAAK,KAAT,EAAgB;AACd,UAAA,OAAO,CAAC,GAAR,CAAY,kBAAZ,EAAgC,8BAAhC;AACD,SAHI,CAIL;;;AACA,YAAI,KAAK,QAAT,EAAmB;AACjB;AACA;AACA,gBAAM,OAAO,GAAG,cAAc,GAAG,IAAI,CAAC,GAAL,CAAS,CAAT,EAAY,IAAI,CAAC,IAAL,CAAU,IAAI,CAAC,GAAL,CAAS,KAAK,aAAd,IAA+B,IAAI,CAAC,GAAL,CAAS,CAAT,CAAzC,CAAZ,CAAjC;AACA,eAAK,cAAL,GAAsB,KAAK,YAAL,CAAkB,qBAAlB,CAAwC,OAAxC,EAAiD,CAAjD,EAAoD,CAApD,CAAtB;AACD,SALD,MAKO;AACL,eAAK,cAAL,GAAsB,KAAK,YAAL,CAAkB,qBAAlB,CAAwC,SAAxC,EAAmD,CAAnD,EAAsD,CAAtD,CAAtB;AACD;;AACD,aAAK,YAAL,CAAkB,uBAAlB,CAA0C,KAAK,WAA/C,EAA4D,OAA5D,CAAoE,KAAK,cAAzE;AACA,aAAK,cAAL,CAAoB,OAApB,CAA4B,KAAK,YAAL,CAAkB,WAA9C;AACA,aAAK,cAAL,CAAoB,gBAApB,CAAqC,iBAArC,EAAyD,KAAD,IAAgC;AACtF,eAAK,WAAL,CAAiB,KAAK,CAAC,WAAN,CAAkB,cAAlB,CAAiC,CAAjC,CAAjB;AACD,SAFD;AAGD;;AAED,WAAK,WAAL,GAAmB,IAAnB;AACA,WAAK,IAAL;;AACD;;AAEK,EAAA,KAAK,GAAA;;AACT,WAAK,IAAL;;AACA,UAAI,CAAC,KAAK,WAAV,EAAuB;AACrB,cAAM,OAAA,CAAA,iBAAN;AACD;;AAED,YAAM,CAAC,GAAG,KAAK,UAAf;AACA,MAAA,CAAC,CAAC,OAAF,GAAY,KAAZ,C,CAEA;;AACA,YAAM,MAAM,GAAG,KAAK,WAApB;AACA,MAAA,MAAM,CAAC,SAAP,GAAmB,OAAnB,CAA2B,CAAC,IAAI,CAAC,CAAC,IAAF,EAAhC,E,CAEA;;AACA,UAAI,KAAK,cAAL,IAAuB,IAA3B,EAAiC;AAC/B,cAAM,IAAI,GAAG,KAAK,cAAlB;AACA,QAAA,IAAI,CAAC,UAAL;AACD,O,CAED;;;AACA,WAAK,WAAL,GAAmB,SAAnB;AACA,WAAK,UAAL,GAAkB,SAAlB;AACA,WAAK,cAAL,GAAsB,SAAtB;AACA,WAAK,WAAL,GAAmB,KAAnB;AACD,K;AAAA;;AAED,EAAA,IAAI,GAAA;AACF,SAAK,KAAL,GAAa,IAAb;AACD;;AAED,EAAA,MAAM,GAAA;AACJ,SAAK,KAAL,GAAa,KAAb;AACD;;AA7I2B;;AAA9B,OAAA,CAAA,iBAAA,GAAA,iBAAA","sourceRoot":"","sourcesContent":["\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst types_1 = require(\"./types\");\nconst audioworklet_1 = __importDefault(require(\"./audioworklet\"));\nconst audioProcessEvent = 'audioprocess';\nconst baseBufferSize = 4096;\nclass BrowserMicrophone {\n    constructor(isWebkit, sampleRate, apiClient, debug = false) {\n        this.initialized = false;\n        this.muted = false;\n        this.handleAudio = (array) => {\n            if (this.muted) {\n                return;\n            }\n            if (array.length > 0) {\n                this.apiClient.sendAudio(array);\n            }\n        };\n        this.isWebkit = isWebkit;\n        this.apiClient = apiClient;\n        this.sampleRate = sampleRate;\n        this.debug = debug;\n    }\n    initialize(audioContext, opts) {\n        var _a;\n        return __awaiter(this, void 0, void 0, function* () {\n            if (((_a = window.navigator) === null || _a === void 0 ? void 0 : _a.mediaDevices) === undefined) {\n                throw types_1.ErrDeviceNotSupported;\n            }\n            this.audioContext = audioContext;\n            this.resampleRatio = this.audioContext.sampleRate / this.sampleRate;\n            try {\n                this.mediaStream = yield window.navigator.mediaDevices.getUserMedia(opts);\n            }\n            catch (_b) {\n                throw types_1.ErrNoAudioConsent;\n            }\n            this.audioTrack = this.mediaStream.getAudioTracks()[0];\n            // Start audio context if we are dealing with a non-WebKit browser.\n            //\n            // Non-webkit browsers (currently only Chrome on Android)\n            // require that user media is obtained before resuming the audio context.\n            //\n            // If audio context is attempted to be resumed before `mediaDevices.getUserMedia`,\n            // `audioContext.resume()` will hang indefinitely, without being resolved or rejected.\n            if (!this.isWebkit) {\n                yield this.audioContext.resume();\n            }\n            if (window.AudioWorkletNode !== undefined) {\n                const blob = new Blob([audioworklet_1.default], { type: 'text/javascript' });\n                const blobURL = window.URL.createObjectURL(blob);\n                yield this.audioContext.audioWorklet.addModule(blobURL);\n                const speechlyNode = new AudioWorkletNode(this.audioContext, 'speechly-worklet');\n                this.audioContext.createMediaStreamSource(this.mediaStream).connect(speechlyNode);\n                speechlyNode.connect(this.audioContext.destination);\n                if (window.SharedArrayBuffer !== undefined) {\n                    // Chrome, Edge, Firefox, Firefox Android\n                    const controlSAB = new window.SharedArrayBuffer(4 * Int32Array.BYTES_PER_ELEMENT);\n                    const dataSAB = new window.SharedArrayBuffer(1024 * Float32Array.BYTES_PER_ELEMENT);\n                    this.apiClient.postMessage({\n                        type: 'SET_SHARED_ARRAY_BUFFERS',\n                        controlSAB,\n                        dataSAB,\n                    });\n                    speechlyNode.port.postMessage({\n                        type: 'SET_SHARED_ARRAY_BUFFERS',\n                        controlSAB,\n                        dataSAB,\n                    });\n                }\n                else {\n                    if (this.debug) {\n                        console.log('[SpeechlyClient]', 'can not use SharedArrayBuffer');\n                    }\n                    // Opera, Chrome Android, Webview Anroid\n                    speechlyNode.port.onmessage = (event) => {\n                        this.handleAudio(event.data);\n                    };\n                }\n            }\n            else {\n                if (this.debug) {\n                    console.log('[SpeechlyClient]', 'can not use AudioWorkletNode');\n                }\n                // Safari, iOS Safari and Internet Explorer\n                if (this.isWebkit) {\n                    // Multiply base buffer size of 4 kB by the resample ratio rounded up to the next power of 2.\n                    // i.e. for 48 kHz to 16 kHz downsampling, this will be 4096 (base) * 4 = 16384.\n                    const bufSize = baseBufferSize * Math.pow(2, Math.ceil(Math.log(this.resampleRatio) / Math.log(2)));\n                    this.audioProcessor = this.audioContext.createScriptProcessor(bufSize, 1, 1);\n                }\n                else {\n                    this.audioProcessor = this.audioContext.createScriptProcessor(undefined, 1, 1);\n                }\n                this.audioContext.createMediaStreamSource(this.mediaStream).connect(this.audioProcessor);\n                this.audioProcessor.connect(this.audioContext.destination);\n                this.audioProcessor.addEventListener(audioProcessEvent, (event) => {\n                    this.handleAudio(event.inputBuffer.getChannelData(0));\n                });\n            }\n            this.initialized = true;\n            this.mute();\n        });\n    }\n    close() {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.mute();\n            if (!this.initialized) {\n                throw types_1.ErrNotInitialized;\n            }\n            const t = this.audioTrack;\n            t.enabled = false;\n            // Stop all media tracks\n            const stream = this.mediaStream;\n            stream.getTracks().forEach(t => t.stop());\n            // Disconnect and stop ScriptProcessorNode\n            if (this.audioProcessor != null) {\n                const proc = this.audioProcessor;\n                proc.disconnect();\n            }\n            // Unset all audio infrastructure\n            this.mediaStream = undefined;\n            this.audioTrack = undefined;\n            this.audioProcessor = undefined;\n            this.initialized = false;\n        });\n    }\n    mute() {\n        this.muted = true;\n    }\n    unmute() {\n        this.muted = false;\n    }\n}\nexports.BrowserMicrophone = BrowserMicrophone;\n//# sourceMappingURL=browser_microphone.js.map"]},"metadata":{},"sourceType":"script"}