{"ast":null,"code":"\"use strict\";\n\nvar _regeneratorRuntime = require(\"C:/Users/hp/Desktop/Projects/Expense-Tracker/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\");\n\nvar _classCallCheck = require(\"C:/Users/hp/Desktop/Projects/Expense-Tracker/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/classCallCheck\");\n\nvar _createClass = require(\"C:/Users/hp/Desktop/Projects/Expense-Tracker/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/createClass\");\n\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\nvar __importDefault = this && this.__importDefault || function (mod) {\n  return mod && mod.__esModule ? mod : {\n    \"default\": mod\n  };\n};\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar types_1 = require(\"./types\");\n\nvar audioworklet_1 = __importDefault(require(\"./audioworklet\"));\n\nvar audioProcessEvent = 'audioprocess';\nvar baseBufferSize = 4096;\n\nvar BrowserMicrophone = /*#__PURE__*/function () {\n  function BrowserMicrophone(isWebkit, sampleRate, apiClient) {\n    var _this = this;\n\n    var debug = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : false;\n\n    _classCallCheck(this, BrowserMicrophone);\n\n    this.initialized = false;\n    this.muted = false;\n\n    this.handleAudio = function (array) {\n      if (_this.muted) {\n        return;\n      }\n\n      if (array.length > 0) {\n        _this.apiClient.sendAudio(array);\n      }\n    };\n\n    this.isWebkit = isWebkit;\n    this.apiClient = apiClient;\n    this.sampleRate = sampleRate;\n    this.debug = debug;\n  }\n\n  _createClass(BrowserMicrophone, [{\n    key: \"initialize\",\n    value: function initialize(audioContext, opts) {\n      var _a;\n\n      return __awaiter(this, void 0, void 0, /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {\n        var _this2 = this;\n\n        var blob, blobURL, speechlyNode, controlSAB, dataSAB, bufSize;\n        return _regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                if (!(((_a = window.navigator) === null || _a === void 0 ? void 0 : _a.mediaDevices) === undefined)) {\n                  _context.next = 2;\n                  break;\n                }\n\n                throw types_1.ErrDeviceNotSupported;\n\n              case 2:\n                this.audioContext = audioContext;\n                this.resampleRatio = this.audioContext.sampleRate / this.sampleRate;\n                _context.prev = 4;\n                _context.next = 7;\n                return window.navigator.mediaDevices.getUserMedia(opts);\n\n              case 7:\n                this.mediaStream = _context.sent;\n                _context.next = 13;\n                break;\n\n              case 10:\n                _context.prev = 10;\n                _context.t0 = _context[\"catch\"](4);\n                throw types_1.ErrNoAudioConsent;\n\n              case 13:\n                this.audioTrack = this.mediaStream.getAudioTracks()[0]; // Start audio context if we are dealing with a non-WebKit browser.\n                //\n                // Non-webkit browsers (currently only Chrome on Android)\n                // require that user media is obtained before resuming the audio context.\n                //\n                // If audio context is attempted to be resumed before `mediaDevices.getUserMedia`,\n                // `audioContext.resume()` will hang indefinitely, without being resolved or rejected.\n\n                if (this.isWebkit) {\n                  _context.next = 17;\n                  break;\n                }\n\n                _context.next = 17;\n                return this.audioContext.resume();\n\n              case 17:\n                if (!(window.AudioWorkletNode !== undefined)) {\n                  _context.next = 28;\n                  break;\n                }\n\n                blob = new Blob([audioworklet_1.default], {\n                  type: 'text/javascript'\n                });\n                blobURL = window.URL.createObjectURL(blob);\n                _context.next = 22;\n                return this.audioContext.audioWorklet.addModule(blobURL);\n\n              case 22:\n                speechlyNode = new AudioWorkletNode(this.audioContext, 'speechly-worklet');\n                this.audioContext.createMediaStreamSource(this.mediaStream).connect(speechlyNode);\n                speechlyNode.connect(this.audioContext.destination);\n\n                if (window.SharedArrayBuffer !== undefined) {\n                  // Chrome, Edge, Firefox, Firefox Android\n                  controlSAB = new window.SharedArrayBuffer(4 * Int32Array.BYTES_PER_ELEMENT);\n                  dataSAB = new window.SharedArrayBuffer(1024 * Float32Array.BYTES_PER_ELEMENT);\n                  this.apiClient.postMessage({\n                    type: 'SET_SHARED_ARRAY_BUFFERS',\n                    controlSAB: controlSAB,\n                    dataSAB: dataSAB\n                  });\n                  speechlyNode.port.postMessage({\n                    type: 'SET_SHARED_ARRAY_BUFFERS',\n                    controlSAB: controlSAB,\n                    dataSAB: dataSAB\n                  });\n                } else {\n                  if (this.debug) {\n                    console.log('[SpeechlyClient]', 'can not use SharedArrayBuffer');\n                  } // Opera, Chrome Android, Webview Anroid\n\n\n                  speechlyNode.port.onmessage = function (event) {\n                    _this2.handleAudio(event.data);\n                  };\n                }\n\n                _context.next = 33;\n                break;\n\n              case 28:\n                if (this.debug) {\n                  console.log('[SpeechlyClient]', 'can not use AudioWorkletNode');\n                } // Safari, iOS Safari and Internet Explorer\n\n\n                if (this.isWebkit) {\n                  // Multiply base buffer size of 4 kB by the resample ratio rounded up to the next power of 2.\n                  // i.e. for 48 kHz to 16 kHz downsampling, this will be 4096 (base) * 4 = 16384.\n                  bufSize = baseBufferSize * Math.pow(2, Math.ceil(Math.log(this.resampleRatio) / Math.log(2)));\n                  this.audioProcessor = this.audioContext.createScriptProcessor(bufSize, 1, 1);\n                } else {\n                  this.audioProcessor = this.audioContext.createScriptProcessor(undefined, 1, 1);\n                }\n\n                this.audioContext.createMediaStreamSource(this.mediaStream).connect(this.audioProcessor);\n                this.audioProcessor.connect(this.audioContext.destination);\n                this.audioProcessor.addEventListener(audioProcessEvent, function (event) {\n                  _this2.handleAudio(event.inputBuffer.getChannelData(0));\n                });\n\n              case 33:\n                this.initialized = true;\n                this.mute();\n\n              case 35:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this, [[4, 10]]);\n      }));\n    }\n  }, {\n    key: \"close\",\n    value: function close() {\n      return __awaiter(this, void 0, void 0, /*#__PURE__*/_regeneratorRuntime.mark(function _callee2() {\n        var t, stream, proc;\n        return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n          while (1) {\n            switch (_context2.prev = _context2.next) {\n              case 0:\n                this.mute();\n\n                if (this.initialized) {\n                  _context2.next = 3;\n                  break;\n                }\n\n                throw types_1.ErrNotInitialized;\n\n              case 3:\n                t = this.audioTrack;\n                t.enabled = false; // Stop all media tracks\n\n                stream = this.mediaStream;\n                stream.getTracks().forEach(function (t) {\n                  return t.stop();\n                }); // Disconnect and stop ScriptProcessorNode\n\n                if (this.audioProcessor != null) {\n                  proc = this.audioProcessor;\n                  proc.disconnect();\n                } // Unset all audio infrastructure\n\n\n                this.mediaStream = undefined;\n                this.audioTrack = undefined;\n                this.audioProcessor = undefined;\n                this.initialized = false;\n\n              case 12:\n              case \"end\":\n                return _context2.stop();\n            }\n          }\n        }, _callee2, this);\n      }));\n    }\n  }, {\n    key: \"mute\",\n    value: function mute() {\n      this.muted = true;\n    }\n  }, {\n    key: \"unmute\",\n    value: function unmute() {\n      this.muted = false;\n    }\n  }]);\n\n  return BrowserMicrophone;\n}();\n\nexports.BrowserMicrophone = BrowserMicrophone;","map":{"version":3,"sources":["../../src/microphone/browser_microphone.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA,IAAA,OAAA,GAAA,OAAA,CAAA,SAAA,CAAA;;AAEA,IAAA,cAAA,GAAA,eAAA,CAAA,OAAA,CAAA,gBAAA,CAAA,CAAA;;AAEA,IAAM,iBAAiB,GAAG,cAA1B;AACA,IAAM,cAAc,GAAG,IAAvB;;IAEa,iB;AAqBX,6BAAY,QAAZ,EAA+B,UAA/B,EAAmD,SAAnD,EAA+F;AAAA;;AAAA,QAAtB,KAAsB,uEAAL,KAAK;;AAAA;;AAfvF,SAAA,WAAA,GAAuB,KAAvB;AACA,SAAA,KAAA,GAAiB,KAAjB;;AAwIS,SAAA,WAAA,GAAc,UAAC,KAAD,EAA8B;AAC3D,UAAI,KAAI,CAAC,KAAT,EAAgB;AACd;AACD;;AACD,UAAI,KAAK,CAAC,MAAN,GAAe,CAAnB,EAAsB;AACpB,QAAA,KAAI,CAAC,SAAL,CAAe,SAAf,CAAyB,KAAzB;AACD;AACF,KAPgB;;AAzHf,SAAK,QAAL,GAAgB,QAAhB;AACA,SAAK,SAAL,GAAiB,SAAjB;AACA,SAAK,UAAL,GAAkB,UAAlB;AACA,SAAK,KAAL,GAAa,KAAb;AACD;;;;WAEK,oBAAW,YAAX,EAAuC,IAAvC,EAAmE;;;;;;;;;;;sBACnE,CAAA,CAAA,EAAA,GAAA,MAAM,CAAC,SAAP,MAAgB,IAAhB,IAAgB,EAAA,KAAA,KAAA,CAAhB,GAAgB,KAAA,CAAhB,GAAgB,EAAA,CAAE,YAAlB,MAAmC,S;;;;;sBAC/B,OAAA,CAAA,qB;;;AAGR,qBAAK,YAAL,GAAoB,YAApB;AACA,qBAAK,aAAL,GAAqB,KAAK,YAAL,CAAkB,UAAlB,GAA+B,KAAK,UAAzD;;;AAGqB,uBAAM,MAAM,CAAC,SAAP,CAAiB,YAAjB,CAA8B,YAA9B,CAA2C,IAA3C,CAAN;;;AAAnB,qBAAK,W;;;;;;;sBAEC,OAAA,CAAA,iB;;;AAGR,qBAAK,UAAL,GAAkB,KAAK,WAAL,CAAiB,cAAjB,GAAkC,CAAlC,CAAlB,C,CAEA;AACA;AACA;AACA;AACA;AACA;AACA;;oBACK,KAAK,Q;;;;;;AACR,uBAAM,KAAK,YAAL,CAAkB,MAAlB,EAAN;;;sBAGE,MAAM,CAAC,gBAAP,KAA4B,S;;;;;AACxB,gBAAA,I,GAAO,IAAI,IAAJ,CAAS,CAAC,cAAA,CAAA,OAAD,CAAT,EAAyB;AAAE,kBAAA,IAAI,EAAE;AAAR,iBAAzB,C;AACP,gBAAA,O,GAAU,MAAM,CAAC,GAAP,CAAW,eAAX,CAA2B,IAA3B,C;;AAChB,uBAAM,KAAK,YAAL,CAAkB,YAAlB,CAA+B,SAA/B,CAAyC,OAAzC,CAAN;;;AACM,gBAAA,Y,GAAe,IAAI,gBAAJ,CAAqB,KAAK,YAA1B,EAAwC,kBAAxC,C;AACrB,qBAAK,YAAL,CAAkB,uBAAlB,CAA0C,KAAK,WAA/C,EAA4D,OAA5D,CAAoE,YAApE;AACA,gBAAA,YAAY,CAAC,OAAb,CAAqB,KAAK,YAAL,CAAkB,WAAvC;;AACA,oBAAI,MAAM,CAAC,iBAAP,KAA6B,SAAjC,EAA4C;AAC1C;AACM,kBAAA,UAFoC,GAEvB,IAAI,MAAM,CAAC,iBAAX,CAA6B,IAAI,UAAU,CAAC,iBAA5C,CAFuB;AAGpC,kBAAA,OAHoC,GAG1B,IAAI,MAAM,CAAC,iBAAX,CAA6B,OAAO,YAAY,CAAC,iBAAjD,CAH0B;AAI1C,uBAAK,SAAL,CAAe,WAAf,CAA2B;AACzB,oBAAA,IAAI,EAAE,0BADmB;AAEzB,oBAAA,UAAU,EAAV,UAFyB;AAGzB,oBAAA,OAAO,EAAP;AAHyB,mBAA3B;AAKA,kBAAA,YAAY,CAAC,IAAb,CAAkB,WAAlB,CAA8B;AAC5B,oBAAA,IAAI,EAAE,0BADsB;AAE5B,oBAAA,UAAU,EAAV,UAF4B;AAG5B,oBAAA,OAAO,EAAP;AAH4B,mBAA9B;AAKD,iBAdD,MAcO;AACL,sBAAI,KAAK,KAAT,EAAgB;AACd,oBAAA,OAAO,CAAC,GAAR,CAAY,kBAAZ,EAAgC,+BAAhC;AACD,mBAHI,CAIL;;;AACA,kBAAA,YAAY,CAAC,IAAb,CAAkB,SAAlB,GAA8B,UAAC,KAAD,EAAwB;AACpD,oBAAA,MAAI,CAAC,WAAL,CAAiB,KAAK,CAAC,IAAvB;AACD,mBAFD;AAGD;;;;;;AAED,oBAAI,KAAK,KAAT,EAAgB;AACd,kBAAA,OAAO,CAAC,GAAR,CAAY,kBAAZ,EAAgC,8BAAhC;AACD,iB,CACD;;;AACA,oBAAI,KAAK,QAAT,EAAmB;AACjB;AACA;AACM,kBAAA,OAHW,GAGD,cAAc,GAAG,IAAI,CAAC,GAAL,CAAS,CAAT,EAAY,IAAI,CAAC,IAAL,CAAU,IAAI,CAAC,GAAL,CAAS,KAAK,aAAd,IAA+B,IAAI,CAAC,GAAL,CAAS,CAAT,CAAzC,CAAZ,CAHhB;AAIjB,uBAAK,cAAL,GAAsB,KAAK,YAAL,CAAkB,qBAAlB,CAAwC,OAAxC,EAAiD,CAAjD,EAAoD,CAApD,CAAtB;AACD,iBALD,MAKO;AACL,uBAAK,cAAL,GAAsB,KAAK,YAAL,CAAkB,qBAAlB,CAAwC,SAAxC,EAAmD,CAAnD,EAAsD,CAAtD,CAAtB;AACD;;AACD,qBAAK,YAAL,CAAkB,uBAAlB,CAA0C,KAAK,WAA/C,EAA4D,OAA5D,CAAoE,KAAK,cAAzE;AACA,qBAAK,cAAL,CAAoB,OAApB,CAA4B,KAAK,YAAL,CAAkB,WAA9C;AACA,qBAAK,cAAL,CAAoB,gBAApB,CAAqC,iBAArC,EAAwD,UAAC,KAAD,EAAgC;AACtF,kBAAA,MAAI,CAAC,WAAL,CAAiB,KAAK,CAAC,WAAN,CAAkB,cAAlB,CAAiC,CAAjC,CAAjB;AACD,iBAFD;;;AAKF,qBAAK,WAAL,GAAmB,IAAnB;AACA,qBAAK,IAAL;;;;;;;;;AACD;;;WAEK,iBAAK;;;;;;;AACT,qBAAK,IAAL;;oBACK,KAAK,W;;;;;sBACF,OAAA,CAAA,iB;;;AAGF,gBAAA,C,GAAI,KAAK,U;AACf,gBAAA,CAAC,CAAC,OAAF,GAAY,KAAZ,C,CAEA;;AACM,gBAAA,M,GAAS,KAAK,W;AACpB,gBAAA,MAAM,CAAC,SAAP,GAAmB,OAAnB,CAA2B,UAAA,CAAC;AAAA,yBAAI,CAAC,CAAC,IAAF,EAAJ;AAAA,iBAA5B,E,CAEA;;AACA,oBAAI,KAAK,cAAL,IAAuB,IAA3B,EAAiC;AACzB,kBAAA,IADyB,GAClB,KAAK,cADa;AAE/B,kBAAA,IAAI,CAAC,UAAL;AACD,iB,CAED;;;AACA,qBAAK,WAAL,GAAmB,SAAnB;AACA,qBAAK,UAAL,GAAkB,SAAlB;AACA,qBAAK,cAAL,GAAsB,SAAtB;AACA,qBAAK,WAAL,GAAmB,KAAnB;;;;;;;;;AACD;;;WAED,gBAAI;AACF,WAAK,KAAL,GAAa,IAAb;AACD;;;WAED,kBAAM;AACJ,WAAK,KAAL,GAAa,KAAb;AACD;;;;;;AA7IH,OAAA,CAAA,iBAAA,GAAA,iBAAA","sourceRoot":"","sourcesContent":["\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst types_1 = require(\"./types\");\nconst audioworklet_1 = __importDefault(require(\"./audioworklet\"));\nconst audioProcessEvent = 'audioprocess';\nconst baseBufferSize = 4096;\nclass BrowserMicrophone {\n    constructor(isWebkit, sampleRate, apiClient, debug = false) {\n        this.initialized = false;\n        this.muted = false;\n        this.handleAudio = (array) => {\n            if (this.muted) {\n                return;\n            }\n            if (array.length > 0) {\n                this.apiClient.sendAudio(array);\n            }\n        };\n        this.isWebkit = isWebkit;\n        this.apiClient = apiClient;\n        this.sampleRate = sampleRate;\n        this.debug = debug;\n    }\n    initialize(audioContext, opts) {\n        var _a;\n        return __awaiter(this, void 0, void 0, function* () {\n            if (((_a = window.navigator) === null || _a === void 0 ? void 0 : _a.mediaDevices) === undefined) {\n                throw types_1.ErrDeviceNotSupported;\n            }\n            this.audioContext = audioContext;\n            this.resampleRatio = this.audioContext.sampleRate / this.sampleRate;\n            try {\n                this.mediaStream = yield window.navigator.mediaDevices.getUserMedia(opts);\n            }\n            catch (_b) {\n                throw types_1.ErrNoAudioConsent;\n            }\n            this.audioTrack = this.mediaStream.getAudioTracks()[0];\n            // Start audio context if we are dealing with a non-WebKit browser.\n            //\n            // Non-webkit browsers (currently only Chrome on Android)\n            // require that user media is obtained before resuming the audio context.\n            //\n            // If audio context is attempted to be resumed before `mediaDevices.getUserMedia`,\n            // `audioContext.resume()` will hang indefinitely, without being resolved or rejected.\n            if (!this.isWebkit) {\n                yield this.audioContext.resume();\n            }\n            if (window.AudioWorkletNode !== undefined) {\n                const blob = new Blob([audioworklet_1.default], { type: 'text/javascript' });\n                const blobURL = window.URL.createObjectURL(blob);\n                yield this.audioContext.audioWorklet.addModule(blobURL);\n                const speechlyNode = new AudioWorkletNode(this.audioContext, 'speechly-worklet');\n                this.audioContext.createMediaStreamSource(this.mediaStream).connect(speechlyNode);\n                speechlyNode.connect(this.audioContext.destination);\n                if (window.SharedArrayBuffer !== undefined) {\n                    // Chrome, Edge, Firefox, Firefox Android\n                    const controlSAB = new window.SharedArrayBuffer(4 * Int32Array.BYTES_PER_ELEMENT);\n                    const dataSAB = new window.SharedArrayBuffer(1024 * Float32Array.BYTES_PER_ELEMENT);\n                    this.apiClient.postMessage({\n                        type: 'SET_SHARED_ARRAY_BUFFERS',\n                        controlSAB,\n                        dataSAB,\n                    });\n                    speechlyNode.port.postMessage({\n                        type: 'SET_SHARED_ARRAY_BUFFERS',\n                        controlSAB,\n                        dataSAB,\n                    });\n                }\n                else {\n                    if (this.debug) {\n                        console.log('[SpeechlyClient]', 'can not use SharedArrayBuffer');\n                    }\n                    // Opera, Chrome Android, Webview Anroid\n                    speechlyNode.port.onmessage = (event) => {\n                        this.handleAudio(event.data);\n                    };\n                }\n            }\n            else {\n                if (this.debug) {\n                    console.log('[SpeechlyClient]', 'can not use AudioWorkletNode');\n                }\n                // Safari, iOS Safari and Internet Explorer\n                if (this.isWebkit) {\n                    // Multiply base buffer size of 4 kB by the resample ratio rounded up to the next power of 2.\n                    // i.e. for 48 kHz to 16 kHz downsampling, this will be 4096 (base) * 4 = 16384.\n                    const bufSize = baseBufferSize * Math.pow(2, Math.ceil(Math.log(this.resampleRatio) / Math.log(2)));\n                    this.audioProcessor = this.audioContext.createScriptProcessor(bufSize, 1, 1);\n                }\n                else {\n                    this.audioProcessor = this.audioContext.createScriptProcessor(undefined, 1, 1);\n                }\n                this.audioContext.createMediaStreamSource(this.mediaStream).connect(this.audioProcessor);\n                this.audioProcessor.connect(this.audioContext.destination);\n                this.audioProcessor.addEventListener(audioProcessEvent, (event) => {\n                    this.handleAudio(event.inputBuffer.getChannelData(0));\n                });\n            }\n            this.initialized = true;\n            this.mute();\n        });\n    }\n    close() {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.mute();\n            if (!this.initialized) {\n                throw types_1.ErrNotInitialized;\n            }\n            const t = this.audioTrack;\n            t.enabled = false;\n            // Stop all media tracks\n            const stream = this.mediaStream;\n            stream.getTracks().forEach(t => t.stop());\n            // Disconnect and stop ScriptProcessorNode\n            if (this.audioProcessor != null) {\n                const proc = this.audioProcessor;\n                proc.disconnect();\n            }\n            // Unset all audio infrastructure\n            this.mediaStream = undefined;\n            this.audioTrack = undefined;\n            this.audioProcessor = undefined;\n            this.initialized = false;\n        });\n    }\n    mute() {\n        this.muted = true;\n    }\n    unmute() {\n        this.muted = false;\n    }\n}\nexports.BrowserMicrophone = BrowserMicrophone;\n//# sourceMappingURL=browser_microphone.js.map"]},"metadata":{},"sourceType":"script"}